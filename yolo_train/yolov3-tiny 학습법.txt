# 필수 !! ubuntu 16.04 버전
# opencv 설치 => https://pgmrlsh.tistory.com/3?category=766787
# cmake 설치
# 파이썬(최신버전), 파이참(최신버전,jetbrains 에서) 설치





< 1 > darknet 설치
1. 원하는 darknet 을 설치하고자 하는 폴더로 들어가 터미널을 연다.
git clone https://github.com/pjreddie/darknet 

2. Makefile 에 들어가 OPENCV=1 로 변경. CUDA 를 사용한다면 GPU=1로 변경한다.

3. 터미널을 열고 cd darknet 입력
make 입력



< 2 > 학습데이터 만들기
1. Yolo_mark 프로그램 사용.

2. Yolo_mark 프로그램을 사용하기 위해서는 학습할 사진들이 필요하다. 나는 학습 대상을 동영상으로 찍어서 파이썬에서 모든 프레임들을 캡쳐해서 사진으로 저장하는 방법을 이용하여 학습데이터를 모았다. 이 소스코드는 따로 첨부하겠다.(첨부 : Video_Capture.py)

3. 모든 사진중에서 학습할 데이터만 따로 잘라낼 필요는 없다. yolo_mark 프로그램에서 직접 하면 된다.

4. yolo_mark/x64/Release/data/img 디렉토리에 있는 예시파일들 모두 삭제.(필요없음. 예시용임)

5. 본인이 직접 모든 사진파일들을 yolo_mark/x64/Release/data/img 경로에 저장.
	
6. x64/Release/data/obj.data 파일의 classes를 학습시 킬 물체의 수로 바꾼다.(1개만 할거면 classes = 1)

7. x64/Release/data/obj.names 에서 학습 시킬 class의 이름도 작성해야한다. 만약 대상의 이름을 ipot을 학습시킨다면 ipot 이라고 입력하면 된다.

8. yolo_mark 를 실행시킨다. 실행방법은 터미널창을 열고 다음을 차례대로 입력한다.
cd yolo_mark
cmake .
make
sh linux_mark.sh

9. yolo_mark 가 열리면서 본인이 모았던 사진들이 뜰것이다. 그 사진들에서 학습할 대상에 Bounding Box 를 체크해준다. https://pgmrlsh.tistory.com/4
h: 단축키들에 대한 설명이 이미지 상단에 표시된다. 다시 누르면 꺼진다.
space bar: 다음 이미지로 넘어간다.
좌우 화살표: 이미지를 이전, 다음 이미지로 넘어간다고 써있는데 나는 안됐었다...
c: Bounding Box 초기화(clear)
z: 마지막 Bounding Box를 지운다.(undo)

===> tip) Bounding Box를 체크하고 space bar 누르면서 넘어가면 되는데 간혹 오류로 열리지 않는 사진이 있다면
괜히 Bounding Box 만들어서 안좋은 데이터 만들지 말고 위에 사진 옆에 오른쪽 방향키 눌러서 제대로 된 사진 나올때 까지 넘기면 된다.

10. 그렇게 모두 학습시키면 data/train.txt 파일에 보면 학습된 목록이 나열된다. 이 파일을 darknet 으로 가져와서 내용을 일부 수정해야한다.




< 3 > 욜로파일 수정 및 디렉토리 변경 
1. yolov3-tiny.cfg 파일 열어서 가장 아래로 간다.

2. [yolo]라고 되어있는곳 에서 classes를 수정한다. 학습시키는 데이터 갯수를 넣으면 된다.

3. [yolo] 바로위에있는 171lines에 filters를 수정. (classes + 5) * 3 을 넣으면 된다. 
ex) 학습시키는 데이터가 1개라면 classes = 1, filters = 18. (단, yolov3 기준이고 yolov2,yolov1은 filters 계산 식이 다르다.)

4. training을 위한 convolutional 파일을 받는다.(darknet19_448.conv.23)  <--  http://pjreddie.com/media/files/darknet19_448.conv.23 를 이용.

5. 이제 준비된 cfg파일(yolov3-tiny.cfg), 훈련용 weights 파일(darknet19_448.conv.23), train.txt, names파일(obg.names), data파일(obj.data) 의 디렉토리를 변경해준다.
- darknet/data 에 있어야하는 파일 : train.txt, .names파일, .data파일
- darknet 에 있어야 하는 파일 : .cfg파일, darknet19_448.conv.23
- darknet/img : 캡쳐한 이미지 파일들과 그에 대응하는 txt파일

===> 이 때 train.txt 파일은 경로가 x64/Release/data/img/frame119.jpg 처럼 되어있을 텐데 이때 x64/Release/ 를 삭제하고 data/img/frame119.jpg 꼴로 남겨놔야 컴퓨터가 제대로 파일을 찾을 수 있다. 

6. 이제 모든 준비가 끝났으니 학습을 시작한다.
터미널창을 열고 cd darknet -> 
./darknet detector train data/obj.data yolov3-tiny.cfg darknet19_448.conv.23

7. 학습이 완료되는데 시간이 좀 소요된다... (tiny 라고해도 cpu만 있는 노트북은 데이터 300개 하는데도 3시간 이상 소요됨.)

8. 학습이 완료되면 첨부한 openCV_yoloTiny_basic.py 실행.

9. openCV_yoloTiny_basic.py 이 있는 폴더경로로 간다. 가서 학습시킨 weights 파일과 cfg파일, names파일을 붙여넣는다.

10. net = cv2.dnn.readNet 괄호안에 각각 weights 파일과 cfg파일을 입력. 학습후 weights 파일은 darknet/backup에 들어간다.
필자는 net = cv2.dnn.readNet("yolov3-tiny_custom_900.weights", "yolov3-tiny_custom.cfg") 으로 입력하였습니다.

10. with open("obj.names", "r") as f: 부분에 obj.names 부분에 본인이 학습시킬때 쓴 .names 파일을 입력하면 된다.

11. 실행하면 인식되는것을 볼 수 있다.



< 다른 yolov3-tiny 전용 conv 파일 받아서 training 하기 >
https://eungbean.github.io/2018/11/07/yolo-for-realtime-food-recognition/
=> conv.15가 conv.23 보다 인식률 좋은거같다.


============================================================================
다시한번 trainging : 
./darknet detector train data/obj.data yolov3-tiny_custom.cfg yolov3-tiny.conv.15 로 학습시킴.
convolutional 파일이 달라.

